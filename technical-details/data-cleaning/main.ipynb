{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Cleaning\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- After digesting the instructions, you can delete this cell, these are assignment instructions and do not need to be included in your final submission.  -->\n",
    "\n",
    "{{< include instructions.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code \n",
    "\n",
    "Provide the source code used for this section of the project here.\n",
    "\n",
    "If you're using a package for code organization, you can import it at this point. However, make sure that the **actual workflow steps**—including data processing, analysis, and other key tasks—are conducted and clearly demonstrated on this page. The goal is to show the technical flow of your project, highlighting how the code is executed to achieve your results.\n",
    "\n",
    "If relevant, link to additional documentation or external references that explain any complex components. This section should give readers a clear view of how the project is implemented from a technical perspective.\n",
    "\n",
    "Remember, this page is a technical narrative, NOT just a notebook with a collection of code cells, include in-line Prose, to describe what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cleaning the text\n",
    "\n",
    "def string_cleaner(input_string):\n",
    "    try:\n",
    "        out = re.sub(r\"\"\"\n",
    "                    [,.;@#?!&$-]+\n",
    "                    \\ *          \n",
    "                    \"\"\",\n",
    "                    \" \",\n",
    "                    input_string, flags=re.VERBOSE)\n",
    "        out = re.sub('[’.]+', '', out)\n",
    "        out = re.sub(r'\\\\u[0-9a-fA-F]{4}', '', out)\n",
    "        out = re.sub(r'\\s+', ' ', out)\n",
    "        out = out.lower()\n",
    "    except:\n",
    "        print(\"ERROR\")\n",
    "        out = ''\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean news data\n",
    "def clean_news_data(raw_data_dir, clean_data_dir):\n",
    "    \n",
    "    # Iterate through raw data files\n",
    "    for file_name in os.listdir(raw_data_dir):\n",
    "        if file_name.endswith(\"_raw_text.json\"):  # Process only raw data files\n",
    "            \n",
    "            # Load the raw data\n",
    "            raw_file_path = os.path.join(raw_data_dir, file_name)\n",
    "            with open(raw_file_path, 'r') as raw_file:\n",
    "                raw_data = json.load(raw_file)\n",
    "            \n",
    "            # Clean the data\n",
    "            clean_data = {}\n",
    "            for article in raw_data:\n",
    "                title = article.get('title', '')\n",
    "                description = article.get('description', '')\n",
    "                \n",
    "                if title and description:\n",
    "                    clean_title = string_cleaner(title)\n",
    "                    clean_description = string_cleaner(description)\n",
    "                    clean_data[clean_title] = clean_description\n",
    "            \n",
    "            # Save the cleaned data to a new file\n",
    "            clean_file_name = file_name.replace(\"_raw_text.json\", \"_clean_news.json\")\n",
    "            clean_file_path = os.path.join(clean_data_dir, clean_file_name)\n",
    "            with open(clean_file_path, 'w') as clean_file:\n",
    "                json.dump(clean_data, clean_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "\n",
    "# Directory with raw data files\n",
    "raw_data_dir = \"../../data/raw-data/News_Drivers\"  \n",
    "\n",
    "# Directory for cleaned data files\n",
    "clean_data_dir = \"../../data/processed-data/News_drivers\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the news data\n",
    "clean_news_data(raw_data_dir, clean_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Drivers Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../../data/raw-data/Driver_standings/driver_standings_2000_2023.json\"\n",
    "output_file = \"../../data/processed-data/driver_standings_2000_2023.csv\"\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare a list to store extracted records\n",
    "cleaned_data = []\n",
    "\n",
    "# Loop through each season in the JSON\n",
    "for season, season_data in data.items():\n",
    "    standings_lists = season_data.get('MRData', {}).get('StandingsTable', {}).get('StandingsLists', [])\n",
    "    \n",
    "    for standings in standings_lists:\n",
    "        driver_standings = standings.get('DriverStandings', [])\n",
    "        \n",
    "        for entry in driver_standings:\n",
    "            # Extract required fields\n",
    "            position = entry.get('position', '')\n",
    "            points = entry.get('points', '')\n",
    "            wins = entry.get('wins', '')\n",
    "            driver = entry.get('Driver', {})\n",
    "            constructors = entry.get('Constructors', [])\n",
    "            \n",
    "            # Extract driver and constructor details\n",
    "            given_name = driver.get('givenName', '')\n",
    "            family_name = driver.get('familyName', '')\n",
    "            constructor_id = constructors[0].get('constructorId', '') if constructors else ''\n",
    "            constructor_name = constructors[0].get('name', '') if constructors else ''\n",
    "            \n",
    "            # Append the record to the cleaned data list\n",
    "            cleaned_data.append({\n",
    "                \"Season\": season,\n",
    "                \"Position\": position,\n",
    "                \"FirstName\": given_name,\n",
    "                \"LastName\": family_name,\n",
    "                \"Constructor_ID\": constructor_id,\n",
    "                \"Constructor_Name\": constructor_name,\n",
    "                \"Points\": points,\n",
    "                \"Wins\": wins\n",
    "            })\n",
    "\n",
    "# Convert the list to a Pandas DataFrame\n",
    "df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Circuit Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../../data/raw-data/circuit_data.json\"\n",
    "output_file = \"../../data/processed-data/circuit_data_clean.csv\"\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract circuit data\n",
    "circuits = data.get('MRData', {}).get('CircuitTable', {}).get('Circuits', [])\n",
    "\n",
    "# Prepare a list to store extracted records\n",
    "cleaned_data = []\n",
    "\n",
    "for circuit in circuits:\n",
    "    circuit_id = circuit.get('circuitId', '')\n",
    "    circuit_name = circuit.get('circuitName', '')\n",
    "    country = circuit.get('Location', {}).get('country', '')\n",
    "    latitude = circuit.get('Location', {}).get('lat', '')\n",
    "    longitude = circuit.get('Location', {}).get('long', '')\n",
    "    \n",
    "    # Append to the list\n",
    "    cleaned_data.append({\n",
    "        \"Circuit_ID\": circuit_id,\n",
    "        \"Circuit_Name\": circuit_name,\n",
    "        \"Country\": country,\n",
    "        \"Latitude\": latitude,\n",
    "        \"Longitude\": longitude\n",
    "    })\n",
    "\n",
    "# Convert the list to a Pandas DataFrame\n",
    "df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Race data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning all the race_data and appending them in to a single csv file \n",
    "\n",
    "# input output directory\n",
    "input_dir = \"../../data/raw-data/\"\n",
    "# output directory\n",
    "output_file = \"../../data/processed-data/all_race_results_cleaned.csv\"\n",
    "\n",
    "# creating an output file\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# initialize a list to hold all results\n",
    "all_combined_results = []\n",
    "\n",
    "# process each JSON file in the input directory\n",
    "# they are the only .json files in the directory\n",
    "for file_name in os.listdir(input_dir):\n",
    "    # process only JSON files\n",
    "    if file_name.endswith(\".json\"): \n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        #print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # read the JSON file\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # extract races from the JSON\n",
    "        races = data.get('MRData', {}).get('RaceTable', {}).get('Races', [])\n",
    "        \n",
    "        # prepare a list to hold flattened race results for this file\n",
    "        file_results = []\n",
    "\n",
    "        # loop through each race and flatten its data\n",
    "        for race in races:\n",
    "            # extract required information \n",
    "            race_info = { \n",
    "                \"season\": race.get(\"season\", \"\"),\n",
    "                \"round\": race.get(\"round\", \"\"),\n",
    "                \"raceName\": race.get(\"raceName\", \"\"),\n",
    "                \"url\": race.get(\"url\",\"\"),\n",
    "                \"circuitName\": race.get(\"Circuit\", {}).get(\"circuitName\", \"\"),\n",
    "                \"locality\": race.get(\"Circuit\", {}).get(\"Location\", {}).get(\"locality\", \"\"),\n",
    "                \"country\": race.get(\"Circuit\", {}).get(\"Location\", {}).get(\"country\", \"\"),\n",
    "                \"lat\": race.get(\"Circuit\", {}).get(\"Location\", {}).get(\"lat\", \"\"),\n",
    "                \"long\": race.get(\"Circuit\", {}).get(\"Location\", {}).get(\"long\", \"\"),\n",
    "                \"date\": race.get(\"date\", \"\"),\n",
    "            }\n",
    "            \n",
    "            # extract results and combine with useful details\n",
    "            results = race.get(\"Results\", [])\n",
    "            for result in results:\n",
    "                # combine race-level and result-level data\n",
    "                combined_data = {**race_info, **result}\n",
    "                # add flattened driver and constructor details\n",
    "                combined_data.update({\n",
    "                    \"driverId\": result.get(\"Driver\", {}).get(\"driverId\", \"\"),\n",
    "                    \"driverGivenName\": result.get(\"Driver\", {}).get(\"givenName\", \"\"),\n",
    "                    \"driverFamilyName\": result.get(\"Driver\", {}).get(\"familyName\", \"\"),\n",
    "                    \"constructorId\": result.get(\"Constructor\", {}).get(\"constructorId\", \"\"),\n",
    "                    \"constructorName\": result.get(\"Constructor\", {}).get(\"name\", \"\"),\n",
    "                    \"status\": result.get(\"status\", \"\"),\n",
    "                    \"timeMillis\": result.get(\"Time\", {}).get(\"millis\", \"\"),\n",
    "                    \"time\": result.get(\"Time\", {}).get(\"time\", \"\")\n",
    "                })\n",
    "                file_results.append(combined_data)\n",
    "\n",
    "        # append the results for this file to the combined list\n",
    "        all_combined_results.extend(file_results)\n",
    "\n",
    "# aonvert the combined results to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_combined_results)\n",
    "\n",
    "# aave the combined DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/processed-data/all_race_results_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'round', 'raceName', 'url', 'circuitName', 'locality',\n",
       "       'country', 'lat', 'long', 'date', 'number', 'position', 'positionText',\n",
       "       'points', 'Driver', 'Constructor', 'grid', 'laps', 'status', 'Time',\n",
       "       'FastestLap', 'driverId', 'driverGivenName', 'driverFamilyName',\n",
       "       'constructorId', 'constructorName', 'timeMillis', 'time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['positionText', 'number', 'FastestLap', 'Driver', 'Constructor', 'Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>raceName</th>\n",
       "      <th>url</th>\n",
       "      <th>circuitName</th>\n",
       "      <th>locality</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>grid</th>\n",
       "      <th>laps</th>\n",
       "      <th>status</th>\n",
       "      <th>driverId</th>\n",
       "      <th>driverGivenName</th>\n",
       "      <th>driverFamilyName</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>constructorName</th>\n",
       "      <th>timeMillis</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2010_Bahrain_Gran...</td>\n",
       "      <td>Bahrain International Circuit</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>26.0325</td>\n",
       "      <td>50.5106</td>\n",
       "      <td>2010-03-14</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>Finished</td>\n",
       "      <td>alonso</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>ferrari</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>5960396.0</td>\n",
       "      <td>1:39:20.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2010_Bahrain_Gran...</td>\n",
       "      <td>Bahrain International Circuit</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>26.0325</td>\n",
       "      <td>50.5106</td>\n",
       "      <td>2010-03-14</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>Finished</td>\n",
       "      <td>massa</td>\n",
       "      <td>Felipe</td>\n",
       "      <td>Massa</td>\n",
       "      <td>ferrari</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>5976495.0</td>\n",
       "      <td>+16.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2010_Bahrain_Gran...</td>\n",
       "      <td>Bahrain International Circuit</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>26.0325</td>\n",
       "      <td>50.5106</td>\n",
       "      <td>2010-03-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>Finished</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>mclaren</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>5983578.0</td>\n",
       "      <td>+23.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2010_Bahrain_Gran...</td>\n",
       "      <td>Bahrain International Circuit</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>26.0325</td>\n",
       "      <td>50.5106</td>\n",
       "      <td>2010-03-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>Finished</td>\n",
       "      <td>vettel</td>\n",
       "      <td>Sebastian</td>\n",
       "      <td>Vettel</td>\n",
       "      <td>red_bull</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>5999195.0</td>\n",
       "      <td>+38.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>http://en.wikipedia.org/wiki/2010_Bahrain_Gran...</td>\n",
       "      <td>Bahrain International Circuit</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>26.0325</td>\n",
       "      <td>50.5106</td>\n",
       "      <td>2010-03-14</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>Finished</td>\n",
       "      <td>rosberg</td>\n",
       "      <td>Nico</td>\n",
       "      <td>Rosberg</td>\n",
       "      <td>mercedes</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>6000609.0</td>\n",
       "      <td>+40.213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  round            raceName  \\\n",
       "0    2010      1  Bahrain Grand Prix   \n",
       "1    2010      1  Bahrain Grand Prix   \n",
       "2    2010      1  Bahrain Grand Prix   \n",
       "3    2010      1  Bahrain Grand Prix   \n",
       "4    2010      1  Bahrain Grand Prix   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://en.wikipedia.org/wiki/2010_Bahrain_Gran...   \n",
       "1  http://en.wikipedia.org/wiki/2010_Bahrain_Gran...   \n",
       "2  http://en.wikipedia.org/wiki/2010_Bahrain_Gran...   \n",
       "3  http://en.wikipedia.org/wiki/2010_Bahrain_Gran...   \n",
       "4  http://en.wikipedia.org/wiki/2010_Bahrain_Gran...   \n",
       "\n",
       "                     circuitName locality  country      lat     long  \\\n",
       "0  Bahrain International Circuit   Sakhir  Bahrain  26.0325  50.5106   \n",
       "1  Bahrain International Circuit   Sakhir  Bahrain  26.0325  50.5106   \n",
       "2  Bahrain International Circuit   Sakhir  Bahrain  26.0325  50.5106   \n",
       "3  Bahrain International Circuit   Sakhir  Bahrain  26.0325  50.5106   \n",
       "4  Bahrain International Circuit   Sakhir  Bahrain  26.0325  50.5106   \n",
       "\n",
       "         date  ...  grid  laps    status  driverId driverGivenName  \\\n",
       "0  2010-03-14  ...     3    49  Finished    alonso        Fernando   \n",
       "1  2010-03-14  ...     2    49  Finished     massa          Felipe   \n",
       "2  2010-03-14  ...     4    49  Finished  hamilton           Lewis   \n",
       "3  2010-03-14  ...     1    49  Finished    vettel       Sebastian   \n",
       "4  2010-03-14  ...     5    49  Finished   rosberg            Nico   \n",
       "\n",
       "  driverFamilyName constructorId constructorName timeMillis         time  \n",
       "0           Alonso       ferrari         Ferrari  5960396.0  1:39:20.396  \n",
       "1            Massa       ferrari         Ferrari  5976495.0      +16.099  \n",
       "2         Hamilton       mclaren         McLaren  5983578.0      +23.182  \n",
       "3           Vettel      red_bull        Red Bull  5999195.0      +38.799  \n",
       "4          Rosberg      mercedes        Mercedes  6000609.0      +40.213  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                 0\n",
       "round                  0\n",
       "raceName               0\n",
       "url                    0\n",
       "circuitName            0\n",
       "locality               0\n",
       "country                0\n",
       "lat                    0\n",
       "long                   0\n",
       "date                   0\n",
       "position               0\n",
       "points                 0\n",
       "grid                   0\n",
       "laps                   0\n",
       "status                 0\n",
       "driverId               0\n",
       "driverGivenName        0\n",
       "driverFamilyName       0\n",
       "constructorId          0\n",
       "constructorName        0\n",
       "timeMillis          1291\n",
       "time                1291\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "- The missing vlaues in the 'TimeMillis' and 'time' columns are for those records where the driver did not finish the race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop timeMillis and time columns\n",
    "df = df.drop(columns=['time', 'timeMillis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season              0\n",
       "round               0\n",
       "raceName            0\n",
       "url                 0\n",
       "circuitName         0\n",
       "locality            0\n",
       "country             0\n",
       "lat                 0\n",
       "long                0\n",
       "date                0\n",
       "position            0\n",
       "points              0\n",
       "grid                0\n",
       "laps                0\n",
       "status              0\n",
       "driverId            0\n",
       "driverGivenName     0\n",
       "driverFamilyName    0\n",
       "constructorId       0\n",
       "constructorName     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"../../data/raw-data/weather/race_data_with_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season      0\n",
       "raceName    0\n",
       "url         0\n",
       "weather     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  Sunny\n",
       "1                      Overcast with light rain at start\n",
       "2                                     Mainly cloudy, dry\n",
       "3                                           Cloudy, rain\n",
       "4                                     Mainly cloudy, dry\n",
       "                             ...                        \n",
       "117    Sunny with temperatures reaching up to 27 °C (...\n",
       "118    Dry start, with heavy rain and thunderstorm/mo...\n",
       "119                                                 Rain\n",
       "120                                                Sunny\n",
       "121                                          Warm, Sunny\n",
       "Name: weather, Length: 122, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df['weather']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will try to categorise the weather description into one of the following categories:\n",
    "1. Sunny\n",
    "2. Cloudy\n",
    "3. Rainy\n",
    "4. Windy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_weather(weather_description):\n",
    "\n",
    "    weather_description = weather_description.lower()\n",
    "    \n",
    "    if \"sunny\" in weather_description or \"fine\" in weather_description or \"clear\" in weather_description or \"dry\" in weather_description:\n",
    "        return \"Sunny\"\n",
    "    elif \"cloudy\" in weather_description or \"overcast\" in weather_description or \"cloud\" in weather_description:\n",
    "        return \"Cloudy\"\n",
    "    elif \"rain\" in weather_description or \"thunderstorms\" in weather_description or \"drizzle\" in weather_description:\n",
    "        return \"Rainy\"\n",
    "    elif \"windy\" in weather_description:\n",
    "        return \"Windy\"\n",
    "    # If no match, classify as \"Not Available\"\n",
    "    else:\n",
    "        return \"Not Available\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call classify_weather()\n",
    "weather_df['weather_class'] = weather_df['weather'].apply(classify_weather)\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "output_csv = \"../../data/processed-data/classified_weather_data.csv\"\n",
    "weather_df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_class\n",
       "Sunny            95\n",
       "Cloudy           24\n",
       "Rainy             2\n",
       "Not Available     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df['weather_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
