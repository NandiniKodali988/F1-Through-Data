{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Cleaning\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- After digesting the instructions, you can delete this cell, these are assignment instructions and do not need to be included in your final submission.  -->\n",
    "\n",
    "{{< include instructions.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code \n",
    "\n",
    "Provide the source code used for this section of the project here.\n",
    "\n",
    "If you're using a package for code organization, you can import it at this point. However, make sure that the **actual workflow steps**—including data processing, analysis, and other key tasks—are conducted and clearly demonstrated on this page. The goal is to show the technical flow of your project, highlighting how the code is executed to achieve your results.\n",
    "\n",
    "If relevant, link to additional documentation or external references that explain any complex components. This section should give readers a clear view of how the project is implemented from a technical perspective.\n",
    "\n",
    "Remember, this page is a technical narrative, NOT just a notebook with a collection of code cells, include in-line Prose, to describe what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cleaning the text\n",
    "\n",
    "def string_cleaner(input_string):\n",
    "    try:\n",
    "        out = re.sub(r\"\"\"\n",
    "                    [,.;@#?!&$-]+\n",
    "                    \\ *          \n",
    "                    \"\"\",\n",
    "                    \" \",\n",
    "                    input_string, flags=re.VERBOSE)\n",
    "        out = re.sub('[’.]+', '', out)\n",
    "        out = re.sub(r'\\\\u[0-9a-fA-F]{4}', '', out)\n",
    "        out = re.sub(r'\\s+', ' ', out)\n",
    "        out = out.lower()\n",
    "    except:\n",
    "        print(\"ERROR\")\n",
    "        out = ''\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean news data\n",
    "def clean_news_data(raw_data_dir, clean_data_dir):\n",
    "    \n",
    "    # Iterate through raw data files\n",
    "    for file_name in os.listdir(raw_data_dir):\n",
    "        if file_name.endswith(\"_raw_text.json\"):  # Process only raw data files\n",
    "            \n",
    "            # Load the raw data\n",
    "            raw_file_path = os.path.join(raw_data_dir, file_name)\n",
    "            with open(raw_file_path, 'r') as raw_file:\n",
    "                raw_data = json.load(raw_file)\n",
    "            \n",
    "            # Clean the data\n",
    "            clean_data = {}\n",
    "            for article in raw_data:\n",
    "                title = article.get('title', '')\n",
    "                description = article.get('description', '')\n",
    "                \n",
    "                if title and description:\n",
    "                    clean_title = string_cleaner(title)\n",
    "                    clean_description = string_cleaner(description)\n",
    "                    clean_data[clean_title] = clean_description\n",
    "            \n",
    "            # Save the cleaned data to a new file\n",
    "            clean_file_name = file_name.replace(\"_raw_text.json\", \"_clean_news.json\")\n",
    "            clean_file_path = os.path.join(clean_data_dir, clean_file_name)\n",
    "            with open(clean_file_path, 'w') as clean_file:\n",
    "                json.dump(clean_data, clean_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "\n",
    "# Directory with raw data files\n",
    "raw_data_dir = \"../../data/raw-data/News_Drivers\"  \n",
    "\n",
    "# Directory for cleaned data files\n",
    "clean_data_dir = \"../../data/processed-data/News_drivers\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the news data\n",
    "clean_news_data(raw_data_dir, clean_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Drivers Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../../data/raw-data/Driver_standings/driver_standings_2000_2023.json\"\n",
    "output_file = \"../../data/processed-data/driver_standings_2000_2023.csv\"\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare a list to store extracted records\n",
    "cleaned_data = []\n",
    "\n",
    "# Loop through each season in the JSON\n",
    "for season, season_data in data.items():\n",
    "    standings_lists = season_data.get('MRData', {}).get('StandingsTable', {}).get('StandingsLists', [])\n",
    "    \n",
    "    for standings in standings_lists:\n",
    "        driver_standings = standings.get('DriverStandings', [])\n",
    "        \n",
    "        for entry in driver_standings:\n",
    "            # Extract required fields\n",
    "            position = entry.get('position', '')\n",
    "            points = entry.get('points', '')\n",
    "            wins = entry.get('wins', '')\n",
    "            driver = entry.get('Driver', {})\n",
    "            constructors = entry.get('Constructors', [])\n",
    "            \n",
    "            # Extract driver and constructor details\n",
    "            given_name = driver.get('givenName', '')\n",
    "            family_name = driver.get('familyName', '')\n",
    "            constructor_id = constructors[0].get('constructorId', '') if constructors else ''\n",
    "            constructor_name = constructors[0].get('name', '') if constructors else ''\n",
    "            \n",
    "            # Append the record to the cleaned data list\n",
    "            cleaned_data.append({\n",
    "                \"Season\": season,\n",
    "                \"Position\": position,\n",
    "                \"FirstName\": given_name,\n",
    "                \"LastName\": family_name,\n",
    "                \"Constructor_ID\": constructor_id,\n",
    "                \"Constructor_Name\": constructor_name,\n",
    "                \"Points\": points,\n",
    "                \"Wins\": wins\n",
    "            })\n",
    "\n",
    "# Convert the list to a Pandas DataFrame\n",
    "df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Circuit Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../../data/raw-data/circuit_data.json\"\n",
    "output_file = \"../../data/processed-data/circuit_data_clean.csv\"\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract circuit data\n",
    "circuits = data.get('MRData', {}).get('CircuitTable', {}).get('Circuits', [])\n",
    "\n",
    "# Prepare a list to store extracted records\n",
    "cleaned_data = []\n",
    "\n",
    "for circuit in circuits:\n",
    "    circuit_id = circuit.get('circuitId', '')\n",
    "    circuit_name = circuit.get('circuitName', '')\n",
    "    country = circuit.get('Location', {}).get('country', '')\n",
    "    \n",
    "    # Append to the list\n",
    "    cleaned_data.append({\n",
    "        \"Circuit_ID\": circuit_id,\n",
    "        \"Circuit_Name\": circuit_name,\n",
    "        \"Country\": country\n",
    "    })\n",
    "\n",
    "# Convert the list to a Pandas DataFrame\n",
    "df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
